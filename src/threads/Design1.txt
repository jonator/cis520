
CIS 520 - Programming Project #1
                   
---- GROUP ----

Brandon Michael Fisher   bmfisher@ksu.edu
Jonathan Gregory Ator    jator@ksu.edu
Miles Lawrence McLenon   milesmclenon@ksu.edu

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

A1:
    In timer.c:

    /* stores list of sleeping threads */
    static struct list sleep_queue;

    /* semaphore to protect access to sleep_queue */
    static struct semaphore sleep_queue_sema;

    -----
    In thread.h:

    struct thread
        ...
        int64_t wakeup_tick;                /* Tick value the thread should be woken up on */
        ...
        struct list_elem sleep_elem;        /* List element for sleep_list in timer.c*/
        ...
    };

---- ALGORITHMS ----

A2:
    In timer_sleep(), we sema_down(&sleep_queue_sema) to protect our 
    sleep_queue in case other processes are trying to sleep at the same time.  
    We then disable interrupts and use an auxillary function to insert the thread
    into sleep_queue in non-decreasing order based on the tick when the 
    thread should wake up.  Next sema_up(&sleep_queue_sema), and call
    thread_block() to put the current thread to sleep.

A3:
    In timer_interrupt(), we wake threads from a list that has been
    pre-sorted. This ensures that the maximum number of threads checked
    for the need to wakeup is only 1 greater than the number of threads
    ready to wake at current tick. i.e. if no threads are ready, only 1
    thread will be checked. Furthermore, if there are no sleeping threads
    only the sleep_queue will be checked.

---- SYNCHRONIZATION ----

A4:
    In timer_sleep() sleep_queue can only be modified by one thread at a time due 
    to the protection from sleep_queue_sema.  If multiple threads call timer_sleep()
    simultaneously, one will be blocked on the sema_down instruction until the 
    other has inserted itself into the sleep_queue.  Interrupts are also disabled
    for the insertion and the call to thread_block().  The wakeup_tick is calculated
    before the sleep_queue_sema is downed, so the ticks will be accurate during 
    simultaneous calls to timer_sleep().

A5:
    We use two synchronization strategies to prevent race conditions
    while calling timer_sleep(). First, we use semaphores to prevent
    other threads (possibly on other cores) from attempting to insert
    itself in the sleep_queue. Next, we disable interrupts to prevent
    timer_interrupt() from checking for threads to be awoken at the 
    instant we are inserting a new thread into sleep_list.

---- RATIONALE ----

A6:
    Originally, we used a global list of structs to keep track of 
    threads that were sleeping. The struct consisted of an 'int
    wakeup_tick' to store the sleep duration in ticks, and a
    pointer to a 'struct semaphore;' used as a lock to block the sleeping
    thread and later awaken it once the 'wakeup_tick' duration condition
    was met. This approach had too much overhead when
    many threads were requesting to sleep within a short duration
    of time. Individually allocating and initializing semaphores for each
    sleeping thread was likely the cause of inefficiency. The superior
    approach involved using a list of sleeping threads, and then only
    accessing that data structure using a semaphore.


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

B1:
    In synch.h
    /* Lock. */
    struct lock
    {
        ...
        struct list_elem elem;  /* List_elem used by thread to keep list of all owned locks */
        int promoted_priority;  /* Stores highest donated priority from waiting thread */
    };

    -----
    In thread.h 

    struct thread
    {
        ...
        struct lock *waiting_on;  /* Reference to lock thread is waiting on */
        struct list owned_locks;  /* List of locks thread has acquired */
    }

B2:
    We tightly coupled priority donation to the resource being 
    requested (a lock).  A thread is able to track all locks that 
    it owns via the owned_locks.  It also tracks the lock that it
    is currently waiting on (if any).  Thus a thread's priority can
    be donated to a lock which is then considered 'promoted'.  If
    the thread that owns the requested lock is also waiting on a 
    second lock, the priority is recursively donated to the next 
    lock via: lock->holder->waiting.
    
In synch.h

struct lock 
  {
    ...
    struct list_elem elem;  /* List_elem used by thread to keep list of all owned locks*/
    int promoted_priority;  /* Stores highest donated priority from waiting thread */
  };

---- ALGORITHMS ----

B3:
    When a lock, semaphore, or condition varable is realeased we then 
    wake up the leftmost thread with the highest priority considering 
    priority donation. The thread_get_priority() function is able to 
    get that specific threads highest priority donation based on all
    held locks so that if a threads base priority. By removing the 
    leftmost element ensures that we give equal attention to threads
    that share the highest priority.
    
B4:
    In our implementation of lock_acquire(), we call a promote_lock()
    if the lock is currently in use by another thread (i.e. the semaphore
    value is at 0). If promotion is necessary, the lock's 'promoted_priority'
    would be set to the max of its current value and the priority of the caller of 
    lock_acquire(). In the case of nested donation promote_lock() will recursively 
    promote the priority of any lock holder that the original lock's holder is waiting
    on. This ensures locks held by threads are transitive, regardless of priority.   

B5:
    When lock_release() is called, interrupts are disabled and then the lock 
    is removed from the list of owned_locks of the current thread.  The lock 
    also clears its holder property.  Next, since locks are built on top of 
    semaphores, sema_up continues the release process by searching for the highest 
    priority thread that is waiting for the lock (built on top of the sema).
    Thread_unblock() is called with that thread, which switches its state to 
    ready and adds it to the ready list.  Since the this thread is a higher-
    priority than the thread releasing the lock, thread_unblock() realizes the 
    current thread should immediately yield, allowing the highest priority
    thread in the ready_list to begin execution on the cpu.  If that highest-
    priority thread is the one waiting on the lock that was just released, it 
    will resume execution inside the sema_down() function and continue back up 
    the call stack to acquire the lock.

---- SYNCHRONIZATION ----

B6:
    In a conceivable implementation, the priority donation process would 
    adjust the thread->priority property.  This opens the possibility for 
    race conditions.  i.e. a thread begins to call set_thread_priority() and 
    before it can finish, another thread runs on the cpu, attempts to acquire 
    a lock in the possesion of the first thread, and then attempts to donate 
    its priority.  Thus, a race to the thread->priority that could affect 
    scheduling the next_thread_to_run().
    However, in our implementation the only thing modifying thread->priority is
    the thread_set_priority() method which can only be called by
    the thread itself so there will be no race condintions. Note that we do
    have an owned_locks list that get_priority() used to check for donated prioirty 
    and modification of that list is protected by interupts and a semaphore. 

---- RATIONALE ----

B7:
    To address the problem of priority donation, we originally
    considered using a global data structure to keep
    track of the relationships of the locks (in the form of a tree),
    and would consult that when we wanted to get the next highest
    priority thread to run.
    However, we found it would be more intuitive for each
    thread to include a reference to any lock they are currently 
    waiting on (by means of the waiting_on member of the thread struct).
    The 'waiting_on' reference could then be used to ensure priority donation
    maintains transitivity as threads accumulate locks. The 'waiting_on' reference
    reveals a tree-like structure that represents the relationship of
    threads and locks that could be used in the implementation of such transitivity.
